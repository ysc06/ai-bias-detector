{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11491901,"sourceType":"datasetVersion","datasetId":7203815}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n!pip install -q langgraph\nfrom langgraph.graph import StateGraph, END\nfrom langchain_core.tools import tool\n, END\n#Google API\n!pip install -U google-generativeai\nimport google.generativeai as genai\ngenai.configure(api_key=\"YOUR API KEY\")  \n\nmodel = genai.GenerativeModel(model_name = \"models/gemini-1.5-flash-latest\")\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-20T21:42:51.162924Z","iopub.execute_input":"2025-04-20T21:42:51.163222Z","iopub.status.idle":"2025-04-20T21:42:58.797934Z","shell.execute_reply.started":"2025-04-20T21:42:51.163197Z","shell.execute_reply":"2025-04-20T21:42:58.796815Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# AI Detector for Biased and Politically Sensitive Language in Test Content\n\n## Problem Statement\n\nIn standardized testing, biased or politically sensitive language in test items can unfairly impact certain groups of test takers and ultimately compromise the validity of the assessment. Bias often stems from construct-irrelevant factors‚Äîlike stereotypes or controversial topics‚Äîthat distract from what the test is actually trying to measure. Even when unintentional, this kind of language can undermine fairness and damage the credibility of the test.\n\nDeveloping test items is a lengthy process, and we want to ensure they remain aligned with the current political or social climate, as it can causes significant operation challenges downstream. Manual bias reviews are time-consuing and often inconsistent across reviewers. With increasing demand for fair, inclusive, and scalable assessments, there‚Äôs a growing need for AI-powered tools that can quickly and consistently flag potential issues.\n\n## Project Objective\n\nThis project introduces a prototype **AI Detector** designed to help identify:\n\n- **Linguistic bias** ‚Äî related to gender, race, age, or socioeconomic background  \n- **Politically sensitive content** ‚Äî referencing topics like war, immigration, climate change, or reproductive rights\n\nBy combining **Generative AI methods** like few-shot prompting, structured outputs, and agent-based reasoning, the tool provides clear, categorized feedback on potentially problematic test language.\n\n## How It Works\n\nThe system takes in test item content and uses the following AI techniques to evaluate each sentence:\n\n1. **Few-shot prompting** helps detect and explain bias or politically sensitive language.\n2. **Structured JSON format** with fields like `bias_type`, `explanation`, and `revised_item` for clarity and machine readabiltiy.\n3. **Grounding** that checks the text against a curated list of known biased phrases.\n4. **Embeddings** measure semantic similarity to sensitive topics, even without exact matches.\n4. **Agent decision flow** which dynamically determines whether to flag, rewrite, or pass the item based on these signals. \n\n# # Use Case\nThis is a mini project, proof-of-concept tool aimed at assisting item developers, reviewers, and DEI professionals in identifying content that could raise fairness concerns‚Äîso they can make more informed revisions early in the test development process.\n","metadata":{}},{"cell_type":"code","source":"# Create sample test items\nsample_data = [\n    {\n        \"id\": 1, #gender bias\n        \"text_1\": \"Many believe women are naturally better caregivers than men, making them ideal for teaching or nursing.\",\n        \"text_2\": \"I will not be at home after class today, but my mom is at home. You can stop by my house and give the book to my mom.\"\n    },\n    {\n        \"id\": 2, #political sensitive\n        \"text_1\": \"We‚Äôve observed a decline in the number of Chinese students studying in the U.S. in recent years.\",\n        \"text_2\": \"Recently, I found Chinese merchandizes have become expensive than before.\"\n    },\n    {\n        \"id\": 3, #neutral\n        \"text_1\": \"Learning new languages helps students broaden their understanding of the world.\",\n        \"test_2\": \"Incorporating multilingual education can enhance cognitive development.\"\n    },\n    {\n        \"id\": 4, #socialeconomic bias\n        \"text_1\": \"Students from disadvantaged backgrounds often struggle academically due to lack of parental support and poor home environments.\",\n        \"text_2\": \"Those living in underserved communities may be less motivated to succeed in school.\"\n    },\n    {\n        \"id\": 5, #age\n        \"text_1\": \"Teenagers today lack discipline compared to older generations, which affects their ability to learn.\",\n        \"text_2\": \"Older generations often criticize youth for having diminished focus and perseverance.\"\n    },\n    {\n        \"id\": 6,  # Environmental bias\n        \"text_1\": \"Climate change policies are often exaggerated and primarily serve to limit economic growth under the guise of environmentalism.\",\n        \"text_2\": \"Opponents argue that such regulations stifle innovation and burden developing economies.\"\n    },\n    {\n        \"id\": 7,  # Cultural bias\n        \"text_1\": \"Chinese students are frequently assumed to excel in math and science due to cultural emphasis on discipline and hard work.\",\n        \"text_2\": \"Western education is often portrayed as superior in cultivating independent thinkers compared to its Asian counterparts.\"\n    },\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T21:41:21.359475Z","iopub.execute_input":"2025-04-20T21:41:21.359803Z","iopub.status.idle":"2025-04-20T21:41:21.367108Z","shell.execute_reply.started":"2025-04-20T21:41:21.359778Z","shell.execute_reply":"2025-04-20T21:41:21.366023Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_on_sample_data(sample_data):\n    results = []\n\n    for item in sample_data:\n        text_1 = item.get(\"text_1\", \"\")\n        text_2 = item.get(\"text_2\", \"\")\n        item_id = item.get(\"id\", \"\")\n\n        try:\n            output = graph.invoke({\n                \"text_1\": text_1,\n                \"text_2\": text_2\n            })\n\n            results.append({\n                \"id\": item_id,\n                \"original_text_1\": text_1,\n                \"original_text_2\": text_2,\n                \"classification\": output.get(\"result\", \"N/A\"),\n                \"revised\": output.get(\"revised\", \"N/A\")\n            })\n        except Exception as e:\n            results.append({\n                \"id\": item_id,\n                \"original_text_1\": text_1,\n                \"original_text_2\": text_2,\n                \"classification\": f\"Error: {str(e)}\",\n                \"revised\": \"N/A\"\n            })\n\n    return pd.DataFrame(results)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T21:53:02.138717Z","iopub.execute_input":"2025-04-20T21:53:02.139053Z","iopub.status.idle":"2025-04-20T21:53:02.147218Z","shell.execute_reply.started":"2025-04-20T21:53:02.139022Z","shell.execute_reply":"2025-04-20T21:53:02.145285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@tool\ndef classify_bias(text_1: str, text_2: str) -> dict:\n    \"\"\"\n    Classifies one or two input sentences for bias or political sensitivity using Gemini.\n    \"\"\"\n\n    if text_2.strip():\n        # If both inputs are given\n        prompt = f\"\"\"\nYou are a fairness evaluator reviewing test content for bias and political sensitivity in 2025.\n\nEvaluate the following two sentences. Be especially sensitive to:\n- Stereotypes bias (e.g., about gender, race, age)\n- Political sensitivity (e.g., immigration, U.S.‚ÄìChina tensions)\n- Socioeconomic bias (e.g., parental support, neighborhood quality)\n- Cultural bias (e.g., East vs. West education)\n- Language that may be interpreted differently by marginalized groups\n\nReturn a structured JSON response like this:\n\n{{\n  \"text_1\": {{\n    \"biased\": \"Yes/No\",\n    \"type\": \"...\",\n    \"explanation\": \"...\",\n    \"confidence\": 0.0‚Äì1.0\n  }},\n  \"text_2\": {{\n    \"biased\": \"Yes/No\",\n    \"type\": \"...\",\n    \"explanation\": \"...\",\n    \"confidence\": 0.0‚Äì1.0\n  }}\n}}\n\nText 1: {text_1}\n\nText 2: {text_2}\n\"\"\"\n    else:\n        # If only text_1 is provided\n        prompt = f\"\"\"\nYou are a fairness evaluator reviewing test content for bias and political sensitivity in 2025.\n\nEvaluate the following sentence. Be especially sensitive to:\n- Stereotypes bias (e.g., about gender, race, age)\n- Political sensitivity (e.g., immigration, U.S.‚ÄìChina tensions)\n- Socioeconomic bias (e.g., parental support, neighborhood quality)\n- Cultural bias (e.g., East vs. West education)\n- Language that may be interpreted differently by marginalized groups\n\nReturn a structured JSON response like this:\n\n{{\n  \"text_1\": {{\n    \"biased\": \"Yes/No\",\n    \"type\": \"...\",\n    \"explanation\": \"...\",\n    \"confidence\": 0.0‚Äì1.0\n  }}\n}}\n\nText 1: {text_1}\n\"\"\"\n\n    try:\n        response = model.generate_content(prompt)\n        return {\n            \"text_1\": text_1,\n            \"text_2\": text_2,\n            \"result\": response.text\n        }\n\n    except Exception as e:\n        return {\n            \"text_1\": text_1,\n            \"text_2\": text_2,\n            \"result\": f\"error: {str(e)}\"\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T21:41:21.368289Z","iopub.execute_input":"2025-04-20T21:41:21.368592Z","iopub.status.idle":"2025-04-20T21:41:21.398407Z","shell.execute_reply.started":"2025-04-20T21:41:21.368571Z","shell.execute_reply":"2025-04-20T21:41:21.397594Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Agent will route to only if bias is dected\n\n@tool\ndef generate_rewrite_prompt(text_1: str, text_2: str, result: str) -> dict:\n    \"\"\"\n    Rewrites one or two input sentences to be neutral and inclusive for educational testing.\n    \"\"\"\n\n    if text_2.strip():\n        prompt = f\"\"\"\nRewrite the following two statements to be neutral and inclusive for educational testing.\n\nText 1: {text_1}\nText 2: {text_2}\n\nReturn both rewritten sentences in plain text.\n\"\"\"\n    else:\n        prompt = f\"\"\"\nRewrite the following statement to be neutral and inclusive for educational testing.\n\nText 1: {text_1}\n\nReturn the rewritten sentence in plain text.\n\"\"\"\n\n    try:\n        response = model.generate_content(prompt)\n        return {\n            \"text_1\": text_1,\n            \"text_2\": text_2,\n            \"result\": result,\n            \"revised\": response.text\n        }\n\n    except Exception as e:\n        return {\n            \"text_1\": text_1,\n            \"text_2\": text_2,\n            \"result\": result,\n            \"revised\": f\"error: {str(e)}\"\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T21:50:56.027339Z","iopub.execute_input":"2025-04-20T21:50:56.027735Z","iopub.status.idle":"2025-04-20T21:50:56.039223Z","shell.execute_reply.started":"2025-04-20T21:50:56.027708Z","shell.execute_reply":"2025-04-20T21:50:56.038207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the routing logic \nimport re, json\ndef should_route(state:dict) -> bool: \n\n  \"\"\"\n  Returns True if either text_1 or text_2 is flagged with biased.\n  \"\"\"\n  raw = state.get(\"result\",\"\")\n  try:\n    cleaned = re.sub(r\"^```json\\s*|```$\", \"\", raw.strip(), flags=re.IGNORECASE)\n    parsed = json.loads(cleaned)\n    \n    return (\n          parsed.get(\"text_1\", {}).get(\"biased\", \"\").lower() == \"yes\" or\n          parsed.get(\"text_2\", {}).get(\"biased\", \"\").lower() == \"yes\"\n      )\n\n  except Exception as e:\n      print(\"‚ö†Ô∏è Routing error:\", e)\n      return False# Build the LangGraph logic\nfrom typing import TypedDict\n\n# Create the graph\nclass BiasState(TypedDict):\n  text_1: str\n  text_2: str\n  result: str\n  revised: str\n\nworkflow = StateGraph(state_schema = BiasState) \n\nworkflow.add_node(\"classify\", classify_bias)\nworkflow.add_node(\"rewrite\", generate_rewrite_prompt)\nworkflow.set_entry_point(\"classify\")\n#core: the agent thinks for itself\nworkflow.add_conditional_edges(\n    \"classify\",\n    should_route,\n    {\n        True: \"rewrite\",\n        False: END\n    }\n\n)\n\nworkflow.add_edge(\"rewrite\", END)\ngraph = workflow.compile()\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T21:50:59.240193Z","iopub.execute_input":"2025-04-20T21:50:59.240493Z","iopub.status.idle":"2025-04-20T21:50:59.251470Z","shell.execute_reply.started":"2025-04-20T21:50:59.240472Z","shell.execute_reply":"2025-04-20T21:50:59.250588Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Build the LangGraph logic\nfrom typing import TypedDict\n\n# Create the graph\nclass BiasState(TypedDict):\n  text_1: str\n  text_2: str\n  result: str\n  revised: str\n\nworkflow = StateGraph(state_schema = BiasState) \n\nworkflow.add_node(\"classify\", classify_bias)\nworkflow.add_node(\"rewrite\", generate_rewrite_prompt)\nworkflow.set_entry_point(\"classify\")\n#core: the agent thinks for itself\nworkflow.add_conditional_edges(\n    \"classify\",\n    should_route,\n    {\n        True: \"rewrite\",\n        False: END\n    }\n\n)\n\nworkflow.add_edge(\"rewrite\", END)\ngraph = workflow.compile()\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T21:51:01.536192Z","iopub.execute_input":"2025-04-20T21:51:01.536515Z","iopub.status.idle":"2025-04-20T21:51:01.545482Z","shell.execute_reply.started":"2025-04-20T21:51:01.536493Z","shell.execute_reply":"2025-04-20T21:51:01.544183Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Batch run the LangGraph agent over sample_data\nimport pandas as pd \n\nresults = []\nfor item in sample_data: \n  text_1 = item.get(\"text_1\",\"\")\n  text_2 = item.get(\"text_2\",\"\")\n  item_id = item.get(\"id\",\"\")\n\n  try:\n    output = graph.invoke({\n        \"text_1\": text_1,\n        \"text_2\": text_2\n    })\n\n    results.append({\n        \"id\": item_id,\n        \"original_text_1\": text_1,\n        \"original_text_2\": text_2,\n        \"classification\": output.get(\"result\", \"N/A\"),\n        \"revised_item\": output.get(\"revised\", \"N/A\")\n                    \n    })\n  except Exception as e:\n    results.append({\n        \"id\": item_id,\n        \"original_text_1\": text_1,\n        \"original_text_2\": text_2,\n        \"classficiation\": f\"Error: {str(e)}\",\n        \"revised_item\": \"N/A\"\n    })\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T21:51:03.856090Z","iopub.execute_input":"2025-04-20T21:51:03.856437Z","iopub.status.idle":"2025-04-20T21:51:19.842267Z","shell.execute_reply.started":"2025-04-20T21:51:03.856413Z","shell.execute_reply":"2025-04-20T21:51:19.841337Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Real-time\ndef user_input(text_1: str):\n    try:\n        output = graph.invoke({\n            \"text_1\": text_1,\n            \"text_2\": \"\"  # Empty second input\n        })\n\n        print(\"Classification:\\n\")\n        print(output.get(\"result\", \"No result.\"))\n\n        print(\"\\nRewritten (if biased):\\n\")\n        print(output.get(\"revised\", \"N/A\"))\n\n    except Exception as e:\n        print(f\"Error: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T21:51:19.891745Z","iopub.execute_input":"2025-04-20T21:51:19.892284Z","iopub.status.idle":"2025-04-20T21:51:19.910928Z","shell.execute_reply.started":"2025-04-20T21:51:19.892258Z","shell.execute_reply":"2025-04-20T21:51:19.909700Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## üéØ INTERACTIVE DEMO \n\nUse the input field below to test your sentence(s), or see the sample data. \nThe AI agent will determine whether the sentence contains bias or political sensitivity and suggest a neutral rewrite if applicable.\n","metadata":{}},{"cell_type":"code","source":"USE_SAMPLE_DATA = False  # Flip this to False for real-time\n\nif USE_SAMPLE_DATA:\n    df_sample_results = run_on_sample_data(sample_data)\n    display(df_sample_results)\nelse:\n    text_1 = input(\"Enter text: \")\n    user_input(text_1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T21:57:15.771798Z","iopub.execute_input":"2025-04-20T21:57:15.772091Z","iopub.status.idle":"2025-04-20T21:57:22.167165Z","shell.execute_reply.started":"2025-04-20T21:57:15.772072Z","shell.execute_reply":"2025-04-20T21:57:22.166265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.DataFrame(results)\npd.set_option(\"display.max_colwidth\", None)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T21:41:21.466892Z","iopub.status.idle":"2025-04-20T21:41:21.467311Z","shell.execute_reply.started":"2025-04-20T21:41:21.467110Z","shell.execute_reply":"2025-04-20T21:41:21.467128Z"}},"outputs":[],"execution_count":null}]}